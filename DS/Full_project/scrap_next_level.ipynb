{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from time import sleep\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "final = pd.DataFrame()\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "for j in range (1,333):\n",
    "    url = 'https://www.ambitionbox.com/list-of-companies?page={}'.format(j)\n",
    "    my_header = {\"User-Agent\":\"Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:97.0) Gecko/20100101 Firefox/97.0\", \"Accept\":\"text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,*/*;q=0.8\"}\n",
    "    r = requests.get(url, headers= my_header).text\n",
    "\n",
    "    soup = BeautifulSoup(r, 'html.parser')\n",
    "    company = soup.find_all('div', class_ = 'company-content-wrapper')\n",
    "\n",
    "    name =[]\n",
    "    rating = []\n",
    "    review = []\n",
    "    ctype = []\n",
    "    hq = []\n",
    "    old = []\n",
    "    employees = []\n",
    "\n",
    "    for i in company:\n",
    "\n",
    "        try:\n",
    "            name.append(i.find('h2').text.strip())\n",
    "        except:\n",
    "            name.append(np.nan)\n",
    "\n",
    "        try:\n",
    "            rating.append(i.find_all('p', class_ = 'rating').text.strip())\n",
    "        except:\n",
    "            rating.append(np.nan)\n",
    "\n",
    "        try:\n",
    "            review.append(i.find('a', class_ = 'review-count').text.strip())\n",
    "        except:\n",
    "            review.append(np.nan)\n",
    "\n",
    "        try:\n",
    "            ctype.append(i.find_all('p', class_ = 'infoEntity')[0].text.strip())\n",
    "        except:\n",
    "            ctype.append(np.nan)\n",
    "        \n",
    "        try:\n",
    "            hq.append(i.find_all('p', class_ = 'infoEntity')[1].text.strip())\n",
    "        except:\n",
    "            hq.append(np.nan)\n",
    "\n",
    "        try:\n",
    "            old.append(i.find_all('p', class_ = 'infoEntity')[2].text.strip())\n",
    "        except:\n",
    "            old.append(np.nan)\n",
    "\n",
    "        try:\n",
    "            employees.append(i.find_all('p', class_ = 'infoEntity')[3].text.strip())\n",
    "        except:\n",
    "            employees.append(np.nan)\n",
    "\n",
    "    \n",
    "    d = {\"Name\": name, \"Rating\":rating, \"Review\": review, \"C-Type\": ctype, \"HQ\": hq, \"Old\":old, \"Employees\":employees}\n",
    "\n",
    "    df = pd.DataFrame(d)\n",
    "    final=final.append(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd # library for data analysis\n",
    "import requests # library to handle requests\n",
    "from bs4 import BeautifulSoup # library to parse HTML documents\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n"
     ]
    }
   ],
   "source": [
    "# get the response in the form of html\n",
    "wikiurl=\"https://en.wikipedia.org/wiki/List_of_companies_of_India\"\n",
    "# table_class=\"wikitable sortable jquery-tablesorter\"\n",
    "response=requests.get(wikiurl)\n",
    "print(response.status_code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parse data from the html into a beautifulsoup object\n",
    "soup = BeautifulSoup(response.text, 'html.parser')\n",
    "indiatable=soup.find_all('table',{'class':\"wikitable\"})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            Name           Industry                         Sector  \\\n",
      "0  Aban Offshore          Oil & gas       Exploration & production   \n",
      "1   ABG Shipyard        Industrials                   Shipbuilding   \n",
      "2      ABP Group  Consumer services   Broadcasting & entertainment   \n",
      "3    ACC Limited        Industrials  Building materials & fixtures   \n",
      "4   Action Group       Conglomerate                              -   \n",
      "\n",
      "  Headquarters Founded                              Notes  \n",
      "0      Chennai    1986                 Oil, petrochemical  \n",
      "1    Ahmedabad    1985                   Ship engineering  \n",
      "2      Kolkata    1922                        Media, news  \n",
      "3       Mumbai    1936                             Cement  \n",
      "4    New Delhi    1972  Apparel, chemicals, retail, steel  \n"
     ]
    }
   ],
   "source": [
    "df=pd.read_html(str(indiatable[1]))\n",
    "# convert list to dataframe\n",
    "df=pd.DataFrame(df[0])\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = '/wiki/Aban_Offshore'\n",
    "name = soup.find_all(lambda tag: tag.name == \"Aban Offshore\" and text in tag.text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "print(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "  \n",
    "# sample web page\n",
    "sample_web_page = 'https://en.wikipedia.org/wiki/List_of_companies_of_India'\n",
    "  \n",
    "# call get method to request that page\n",
    "page = requests.get(sample_web_page)\n",
    "  \n",
    "# with the help of beautifulSoup and html parser create soup\n",
    "soup = BeautifulSoup(page.content, \"html.parser\")\n",
    "  \n",
    "text = 'Aban Offshore'\n",
    "  \n",
    "# Search by text with the help of lambda function\n",
    "gfg = soup.find_all(lambda tag: tag.name == \"strong\" and text in tag.text)\n",
    "  \n",
    "print(gfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
